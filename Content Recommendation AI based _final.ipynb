{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hGtJ31EKweij"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Multiply, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, ndcg_score\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "ptNurPvOyS69"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Enhanced Data Processing\n",
        "class DataProcessor:\n",
        "    def __init__(self, content_data, user_data, interaction_data):\n",
        "        self.content_data = content_data\n",
        "        self.user_data = user_data\n",
        "        self.interaction_data = interaction_data\n",
        "        self.content_embeddings = None\n",
        "        self.user_embeddings = None\n",
        "        self.tfidf = TfidfVectorizer(stop_words='english')\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        # Process content data\n",
        "        self.content_data['text_features'] = self.content_data['title'] + ' ' + self.content_data['description']\n",
        "        tfidf_matrix = self.tfidf.fit_transform(self.content_data['text_features'])\n",
        "        self.content_embeddings = tfidf_matrix.toarray()\n",
        "\n",
        "        # Process user data\n",
        "        user_features = self.user_data[['age']].values\n",
        "        self.user_embeddings = self.scaler.fit_transform(user_features)\n",
        "\n",
        "        # Process interaction data\n",
        "        self.interaction_data['timestamp'] = pd.to_datetime(self.interaction_data['timestamp'])\n",
        "        self.interaction_data['recency'] = (pd.Timestamp.now() - self.interaction_data['timestamp']).dt.days\n",
        "\n",
        "    def get_user_profile(self, user_id):\n",
        "        user_interactions = self.interaction_data[self.interaction_data['user_id'] == user_id].sort_values('timestamp').tail(100)\n",
        "        if user_interactions.empty:\n",
        "            return np.zeros(self.content_embeddings.shape[1])\n",
        "\n",
        "        content_ids = user_interactions['content_id'].unique()\n",
        "        weights = 1 / (1 + np.arange(len(content_ids))[::-1])\n",
        "\n",
        "        #Convert 'content_id' to numpy array\n",
        "        content_ids = user_interactions['content_id'].to_numpy()\n",
        "        weighted_sum = np.sum(self.content_embeddings[content_ids] * weights[:, np.newaxis], axis=0) # Index with unique content IDs\n",
        "        return weighted_sum / np.sum(weights)\n",
        "\n",
        "    def get_content_embeddings(self):\n",
        "        return self.content_embeddings\n",
        "\n",
        "    def get_user_embeddings(self):\n",
        "        return self.user_embeddings"
      ],
      "metadata": {
        "id": "DwdcPBebwfRp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHf01KN2wlod"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Enhanced Training and Evaluation\n",
        "class ModelTrainer:\n",
        "    def __init__(self, model, data_processor):\n",
        "        self.model = model\n",
        "        self.data_processor = data_processor\n",
        "\n",
        "    def prepare_data(self):\n",
        "        interactions = self.data_processor.interaction_data\n",
        "        users = interactions['user_id'].values\n",
        "        items = interactions['content_id'].values\n",
        "        labels = interactions['interaction'].values\n",
        "        user_features = self.data_processor.get_user_embeddings()[users]\n",
        "        item_features = self.data_processor.get_content_embeddings()[items]\n",
        "        return users, items, user_features, item_features, labels\n",
        "\n",
        "    def train(self, epochs=20, batch_size=256, validation_split=0.1):\n",
        "        users, items, user_features, item_features, labels = self.prepare_data()\n",
        "        self.model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        history = self.model.fit(\n",
        "            [users, items, user_features, item_features],\n",
        "            labels,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_split=validation_split,\n",
        "            verbose=2\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        users, items, user_features, item_features, labels = test_data\n",
        "        predictions = self.model.predict([users, items, user_features, item_features])\n",
        "        precision = precision_score(labels, predictions.round())\n",
        "        recall = recall_score(labels, predictions.round())\n",
        "        ndcg = ndcg_score(labels.reshape(1, -1), predictions.reshape(1, -1))\n",
        "        return {'precision': precision, 'recall': recall, 'ndcg': ndcg}"
      ],
      "metadata": {
        "id": "QPoWfJXAwpAV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Improved Real-time Update System\n",
        "class RealTimeUpdater:\n",
        "    def __init__(self, model, data_processor):\n",
        "        self.model = model\n",
        "        self.data_processor = data_processor\n",
        "\n",
        "    def update_user_preferences(self, user_id, interaction_data):\n",
        "        new_interactions = pd.DataFrame(interaction_data)\n",
        "        self.data_processor.interaction_data = pd.concat([self.data_processor.interaction_data, new_interactions])\n",
        "        self.data_processor.interaction_data = self.data_processor.interaction_data.sort_values('timestamp').groupby('user_id').tail(1000)  # Keep only the latest 1000 interactions per user\n",
        "\n",
        "    def update_content_features(self, new_content):\n",
        "        new_content_df = pd.DataFrame(new_content)\n",
        "        self.data_processor.content_data = pd.concat([self.data_processor.content_data, new_content_df])\n",
        "        self.data_processor.preprocess_data()  # Recompute content embeddings\n",
        "\n",
        "    def adjust_recommendations(self, user_id, recommendations, recent_interactions):\n",
        "        recent_items = set(recent_interactions['content_id'])\n",
        "        adjusted_recs = [(item, score) for item, score in recommendations if item not in recent_items]\n",
        "        return adjusted_recs[:len(recommendations)]"
      ],
      "metadata": {
        "id": "dccIgjErwsok"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Enhanced Main Recommendation Pipeline\n",
        "class RecommendationSystem:\n",
        "    def __init__(self, data_processor, recommender, trainer, real_time_updater):\n",
        "        self.data_processor = data_processor\n",
        "        self.recommender = recommender\n",
        "        self.trainer = trainer\n",
        "        self.real_time_updater = real_time_updater\n",
        "\n",
        "    def get_recommendations(self, user_id, top_n=10):\n",
        "        user_features = self.data_processor.get_user_embeddings()[user_id]\n",
        "        item_features = self.data_processor.get_content_embeddings()\n",
        "        cf_recs = self.recommender.predict(user_id, user_features, item_features)\n",
        "        cb_recs = self.content_based_recommendations(user_id)\n",
        "        combined_recs = self.combine_recommendations(cf_recs, cb_recs)\n",
        "        recent_interactions = self.data_processor.interaction_data[self.data_processor.interaction_data['user_id'] == user_id].sort_values('timestamp').tail(100)\n",
        "        final_recs = self.real_time_updater.adjust_recommendations(user_id, combined_recs, recent_interactions)\n",
        "        return final_recs[:top_n]\n",
        "\n",
        "    def content_based_recommendations(self, user_id):\n",
        "        user_profile = self.data_processor.get_user_profile(user_id)\n",
        "        content_embeddings = self.data_processor.get_content_embeddings()\n",
        "        content_similarities = cosine_similarity([user_profile], content_embeddings)[0]\n",
        "        return list(enumerate(content_similarities))\n",
        "\n",
        "    def combine_recommendations(self, cf_recs, cb_recs, cf_weight=0.7, cb_weight=0.3):\n",
        "        combined = {}\n",
        "        for content_id, score in cf_recs:\n",
        "            combined[content_id] = score * cf_weight\n",
        "        for content_id, score in cb_recs:\n",
        "            if content_id in combined:\n",
        "                combined[content_id] += score * cb_weight\n",
        "            else:\n",
        "                combined[content_id] = score * cb_weight\n",
        "        return sorted(combined.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    def train_model(self, epochs=20, batch_size=256):\n",
        "        print(\"Starting model training...\")\n",
        "        history = self.trainer.train(epochs=epochs, batch_size=batch_size)\n",
        "        print(\"Model training completed.\")\n",
        "        return history\n",
        "\n",
        "    def update_system(self, new_data):\n",
        "        print(\"Updating system with new data...\")\n",
        "        self.real_time_updater.update_user_preferences(new_data['user_id'], new_data['interactions'])\n",
        "        self.real_time_updater.update_content_features(new_data['new_content'])\n",
        "        print(\"System update completed.\")\n",
        "\n",
        "    def evaluate_recommendations(self, test_data):\n",
        "        print(\"Evaluating recommendation quality...\")\n",
        "        metrics = self.trainer.evaluate(test_data)\n",
        "        print(f\"Evaluation metrics: {metrics}\")\n",
        "        return metrics\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        self.recommender.model.save(filepath)\n",
        "        joblib.dump(self.data_processor, filepath + '_data_processor.joblib')\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        self.recommender.model = tf.keras.models.load_model(filepath)\n",
        "        self.data_processor = joblib.load(filepath + '_data_processor.joblib')"
      ],
      "metadata": {
        "id": "ggFuX-A9wxrc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Initialize components with dummy data\n",
        "    n_users, n_items = 1000, 1000\n",
        "    dummy_content_data = pd.DataFrame({\n",
        "        'content_id': range(n_items),\n",
        "        'title': [f'Item {i}' for i in range(n_items)],\n",
        "        'description': [f'Description for item {i}' for i in range(n_items)]\n",
        "    })\n",
        "    dummy_user_data = pd.DataFrame({\n",
        "        'user_id': range(n_users),\n",
        "        'age': np.random.randint(18, 80, n_users),\n",
        "        'gender': np.random.choice(['M', 'F'], n_users)\n",
        "    })\n",
        "    dummy_interaction_data = pd.DataFrame({\n",
        "        'user_id': np.random.randint(0, n_users, 10000),\n",
        "        'content_id': np.random.randint(0, n_items, 10000),\n",
        "        'interaction': np.random.choice([0, 1], 10000),\n",
        "        'timestamp': pd.date_range(start='1/1/2020', periods=10000)\n",
        "    })\n",
        "\n",
        "    data_processor = DataProcessor(dummy_content_data, dummy_user_data, dummy_interaction_data)\n",
        "    data_processor.preprocess_data()\n",
        "\n",
        "    recommender = HybridRecommender()\n",
        "    model = recommender.build_model(n_users, n_items, data_processor.user_embeddings.shape[1], data_processor.content_embeddings.shape[1])\n",
        "    trainer = ModelTrainer(model, data_processor)\n",
        "    real_time_updater = RealTimeUpdater(model, data_processor)\n",
        "\n",
        "    # Create recommendation system\n",
        "    rec_system = RecommendationSystem(data_processor, recommender, trainer, real_time_updater)\n",
        "\n",
        "    # Train the model\n",
        "    rec_system.train_model(epochs=5, batch_size=256)\n",
        "\n",
        "    # Get recommendations for a user\n",
        "    user_id = 123\n",
        "    recommendations = rec_system.get_recommendations(user_id, top_n=10)\n",
        "    print(f\"Top 10 recommendations for user {user_id}:\")\n",
        "    for content_id, score in recommendations:\n",
        "        print(f\"Content ID: {content_id}, Score: {score}\")\n",
        "\n",
        "    # Update system with new data\n",
        "    new_data = {\n",
        "        'user_id': 123,\n",
        "        'interactions': [{'user_id': 123, 'content_id': 456, 'interaction': 1, 'timestamp': pd.Timestamp.now()}],\n",
        "        'new_content': [{'content_id': 1001, 'title': 'New Video', 'description': 'A brand new video'}]\n",
        "    }\n",
        "    rec_system.update_system(new_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbiWza6cw1kE",
        "outputId": "61e8ecca-c6e5-449e-e6d9-157ee42dfcc0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model training...\n",
            "Epoch 1/5\n",
            "36/36 - 2s - loss: 0.6931 - accuracy: 0.5014 - val_loss: 0.6931 - val_accuracy: 0.5080 - 2s/epoch - 54ms/step\n",
            "Epoch 2/5\n",
            "36/36 - 0s - loss: 0.6925 - accuracy: 0.5983 - val_loss: 0.6931 - val_accuracy: 0.5100 - 190ms/epoch - 5ms/step\n",
            "Epoch 3/5\n",
            "36/36 - 0s - loss: 0.6916 - accuracy: 0.6042 - val_loss: 0.6931 - val_accuracy: 0.5070 - 197ms/epoch - 5ms/step\n",
            "Epoch 4/5\n",
            "36/36 - 0s - loss: 0.6898 - accuracy: 0.8381 - val_loss: 0.6932 - val_accuracy: 0.4920 - 205ms/epoch - 6ms/step\n",
            "Epoch 5/5\n",
            "36/36 - 0s - loss: 0.6865 - accuracy: 0.9519 - val_loss: 0.6932 - val_accuracy: 0.4930 - 210ms/epoch - 6ms/step\n",
            "Model training completed.\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "Top 10 recommendations for user 123:\n",
            "Content ID: 7, Score: 0.4713316280120209\n",
            "Content ID: 4, Score: 0.4708054560893372\n",
            "Content ID: 0, Score: 0.47077616636689457\n",
            "Content ID: 5, Score: 0.47003244941170963\n",
            "Content ID: 8, Score: 0.4696873981231049\n",
            "Content ID: 6, Score: 0.4693278271430329\n",
            "Content ID: 3, Score: 0.4685968357795075\n",
            "Content ID: 1, Score: 0.4676461506360367\n",
            "Content ID: 9, Score: 0.4672353226416901\n",
            "Content ID: 2, Score: 0.46629264836247714\n",
            "Updating system with new data...\n",
            "System update completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ejYnn_x0w6m4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}